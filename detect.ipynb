{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "detect.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPCaeSIKfZrUyiumwwLoQhq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/duypt15uit/CS2225.CH1501/blob/master/detect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSwSzSpwePIE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38d9044c-eaf8-4e1f-9c07-8b64c22a236c"
      },
      "source": [
        "!git clone https://github.com/duypt15uit/CS2225.CH1501.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CS2225.CH1501'...\n",
            "remote: Enumerating objects: 464, done.\u001b[K\n",
            "remote: Counting objects: 100% (464/464), done.\u001b[K\n",
            "remote: Compressing objects: 100% (426/426), done.\u001b[K\n",
            "remote: Total 464 (delta 36), reused 445 (delta 32), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (464/464), 28.79 MiB | 7.79 MiB/s, done.\n",
            "Resolving deltas: 100% (36/36), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6aOBOR8elkw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b48f4e0-385d-47a4-fb5f-a4dcce335311"
      },
      "source": [
        "import tensorflow.keras\r\n",
        "from PIL import Image, ImageOps\r\n",
        "import requests\r\n",
        "from io import BytesIO\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "_DIR = '/content/CS2225.CH1501/DoAnCuoiKi'\r\n",
        "# Disable scientific notation for clarity\r\n",
        "np.set_printoptions(suppress=True)\r\n",
        "\r\n",
        "# Load the model\r\n",
        "model = tensorflow.keras.models.load_model(_DIR + '/model/keras_model.h5')\r\n",
        "\r\n",
        "# Create the array of the right shape to feed into the keras model\r\n",
        "# The 'length' or number of images you can put into the array is\r\n",
        "# determined by the first position in the shape tuple, in this case 1.\r\n",
        "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\r\n",
        "\r\n",
        "# Replace this with the path to your image\r\n",
        "image = Image.open(_DIR + '/sampletest/cat.jpg')\r\n",
        "\r\n",
        "# Or get image from URL\r\n",
        "# url = \"https://static.toiimg.com/thumb/msid-60132235,imgsize-169468,width-800,height-600,resizemode-75/60132235.jpg\"\r\n",
        "# response = requests.get(url)\r\n",
        "# image = Image.open(BytesIO(response.content))\r\n",
        "\r\n",
        "#resize the image to a 224x224 with the same strategy as in TM2:\r\n",
        "#resizing the image to be at least 224x224 and then cropping from the center\r\n",
        "size = (224, 224)\r\n",
        "image = ImageOps.fit(image, size, Image.ANTIALIAS)\r\n",
        "\r\n",
        "#turn the image into a numpy array\r\n",
        "image_array = np.asarray(image)\r\n",
        "\r\n",
        "# display the resized image\r\n",
        "image.show()\r\n",
        "\r\n",
        "# Normalize the image\r\n",
        "normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1\r\n",
        "\r\n",
        "# Load the image into the array\r\n",
        "data[0] = normalized_image_array\r\n",
        "\r\n",
        "# run the inference\r\n",
        "prediction = model.predict(data)\r\n",
        "file_label = open(_DIR+'/model/labels.txt', mode = 'r', encoding = 'utf-8-sig')\r\n",
        "label_texts = lines = file_label.readlines()\r\n",
        "best = 0.0\r\n",
        "index_best = 0\r\n",
        "for i in range(len(prediction[0])):\r\n",
        "  if prediction[0][i] > best:\r\n",
        "    best = prediction[0][i]\r\n",
        "    index_best = i \r\n",
        "print(label_texts[index_best])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f494fb97048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Con Ch√≥\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}